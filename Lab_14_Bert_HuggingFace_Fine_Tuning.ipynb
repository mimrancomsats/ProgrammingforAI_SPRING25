{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimrancomsats/ProgrammingforAI_SPRING25/blob/main/Lab_14_Bert_HuggingFace_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNk0r7mGb7Ib"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh4shvGvb7Ic",
        "outputId": "2f37f639-731b-4f27-8243-00748ce41704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "temp_data = pd.read_csv(\"/content/drive/MyDrive/Programming for AI_SPRING-25/Labs/IMDB Dataset.csv\")\n",
        "df = temp_data.iloc[:10000]\n",
        "\n",
        "#print(texts)\n",
        "\n",
        "X = df['review']\n",
        "Y = df['sentiment']\n",
        "\n",
        "print(type(X))\n",
        "X = X.tolist()\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y).tolist()\n",
        "\n",
        "#print(type(encoder.fit_transform(Y)))\n",
        "print(type(Y))\n",
        "\n",
        "#print(X)\n",
        "#print(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "9880f9755b0049ccb36f77ac5551173b",
            "39c30bc8ce9244d4a563ee07a2bba462",
            "ab1456bb024347018affeddfdf7c7421",
            "a61a6f1c25e64ec5a8cce93cf4383963",
            "8e6a8dface3541d5ae3bd16ba268b303"
          ]
        },
        "id": "WPxRxvN3b7Ie",
        "outputId": "0971e70e-dea4-4177-960f-46df349f7496"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9880f9755b0049ccb36f77ac5551173b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39c30bc8ce9244d4a563ee07a2bba462",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab1456bb024347018affeddfdf7c7421",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a61a6f1c25e64ec5a8cce93cf4383963",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e6a8dface3541d5ae3bd16ba268b303",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm6ra4pvb7Ie",
        "outputId": "13c9da4f-e4b5-4afb-8043-7e960eb6ccbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of X: 10000\n",
            "Size of Y: 10000\n",
            "Size of train_texts: 7000\n",
            "Size of temp_texts: 3000\n",
            "Size of train_labels: 7000\n",
            "Size of temp_labels: 3000\n",
            "Size of val_texts: 1500\n",
            "Size of teest_texts: 1500\n",
            "Size of val_labels: 1500\n",
            "Size of test_labels: 1500\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into train, validation, and test sets\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Size of X: {len(X)}\")\n",
        "print(f\"Size of Y: {len(Y)}\")\n",
        "\n",
        "# Get the sizes of each split\n",
        "train_texts_size = len(train_texts)\n",
        "temp_texts_size = len(temp_texts)\n",
        "train_labels_size = len(train_labels)\n",
        "temp_labels_size = len(temp_labels)\n",
        "\n",
        "# Print the sizes\n",
        "print(f\"Size of train_texts: {train_texts_size}\")\n",
        "print(f\"Size of temp_texts: {temp_texts_size}\")\n",
        "print(f\"Size of train_labels: {train_labels_size}\")\n",
        "print(f\"Size of temp_labels: {temp_labels_size}\")\n",
        "\n",
        "# Get the sizes of each split\n",
        "val_texts_size = len(val_texts)\n",
        "test_texts_size = len(test_texts)\n",
        "val_labels_size = len(val_labels)\n",
        "test_labels_size = len(test_labels)\n",
        "\n",
        "# Print the sizes\n",
        "print(f\"Size of val_texts: {val_texts_size}\")\n",
        "print(f\"Size of teest_texts: {test_texts_size}\")\n",
        "print(f\"Size of val_labels: {val_labels_size}\")\n",
        "print(f\"Size of test_labels: {test_labels_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1qgrs_4b7If"
      },
      "outputs": [],
      "source": [
        "# Tokenize the Dataset\n",
        "def tokenize_dataset(texts, labels, tokenizer, max_length=128):\n",
        "    inputs = tokenizer(texts, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"tf\")\n",
        "    #print(inputs)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    print(input_ids)\n",
        "    print(attention_mask)\n",
        "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)  # Explicitly set dtype\n",
        "    print(labels)\n",
        "    return input_ids, attention_mask, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lTfmrUhb7Ig",
        "outputId": "450b2504-0a51-41a4-ba63-6d1f0ba1e9a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[  101  2129  2204 ... 18908  2075   102]\n",
            " [  101  2067  1999 ... 16625  2108   102]\n",
            " [  101  1045  2481 ...  1999  2023   102]\n",
            " ...\n",
            " [  101  1045  2064 ...  2006  3909   102]\n",
            " [  101  2023  2537 ...     0     0     0]\n",
            " [  101  1045  2001 ...  1000  1037   102]], shape=(7000, 128), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 1 1 1]], shape=(7000, 128), dtype=int32)\n",
            "tf.Tensor([0 0 0 ... 0 1 0], shape=(7000,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[  101  1045  2066 ...  1037  2210   102]\n",
            " [  101  2023  3185 ...  1012  1037   102]\n",
            " [  101  1045  2001 ...  2126  1996   102]\n",
            " ...\n",
            " [  101  2023  2089 ...  4349  1010   102]\n",
            " [  101  1998  1045 ...  2009  1010   102]\n",
            " [  101  2521 15782 ...  5233  1012   102]], shape=(1500, 128), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]], shape=(1500, 128), dtype=int32)\n",
            "tf.Tensor([1 0 1 ... 0 1 1], shape=(1500,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 101 2023 3185 ... 1010 2007  102]\n",
            " [ 101 3649 3047 ... 1010 2169  102]\n",
            " [ 101 1012 1012 ... 2020 2000  102]\n",
            " ...\n",
            " [ 101 2204 2466 ... 2066 2023  102]\n",
            " [ 101 1037 7199 ...    0    0    0]\n",
            " [ 101 6316 1996 ... 7987 1013  102]], shape=(1500, 128), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 1 1 1]], shape=(1500, 128), dtype=int32)\n",
            "tf.Tensor([1 0 0 ... 1 1 0], shape=(1500,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Tokenize datasets\n",
        "train_input_ids, train_attention_mask, train_labels = tokenize_dataset(train_texts, train_labels, tokenizer)\n",
        "val_input_ids, val_attention_mask, val_labels = tokenize_dataset(val_texts, val_labels, tokenizer)\n",
        "test_input_ids, test_attention_mask, test_labels = tokenize_dataset(test_texts, test_labels, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twz2aWXrb7Ig"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(input_ids, attention_mask, labels, batch_size=16):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(({\"input_ids\": input_ids, \"attention_mask\": attention_mask}, labels))\n",
        "    dataset = dataset.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrl0UDSkb7Ih"
      },
      "outputs": [],
      "source": [
        "train_data = create_data_loader(train_input_ids, train_attention_mask, train_labels)\n",
        "val_data = create_data_loader(val_input_ids, val_attention_mask, val_labels)\n",
        "test_data = create_data_loader(test_input_ids, test_attention_mask, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl1Q03Szb7Ih"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_data, val_data, epochs=3, learning_rate=5e-5):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    loss = tf.keras.losses.BinaryCrossentropy()  # Binary crossentropy for binary classification\n",
        "    metric = tf.keras.metrics.BinaryAccuracy()  # Binary accuracy metric\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "    history = model.fit(train_data, validation_data=val_data, epochs=epochs)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ODg-x-lIb7Ii",
        "outputId": "4d96043c-a445-4a64-dff6-b1216ca9e8c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "381/438 [=========================>....] - ETA: 13:35 - loss: 7.7479 - binary_accuracy: 0.4977"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "train_model(model, train_data, val_data)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}