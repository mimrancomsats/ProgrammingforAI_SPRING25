{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimrancomsats/ProgrammingforAI_SPRING25/blob/main/Lab_8_Machine_Learning_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Machine Learning Implementation\n",
        "\n",
        "*   Traditional Implementation\n",
        "*   Sklearn Pipeline Implementation"
      ],
      "metadata": {
        "id": "2asgKb4RCry3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Traditional Machine Learning Implementation**"
      ],
      "metadata": {
        "id": "FbORs_SNsdZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "titanic_data = pd.read_csv('titanic.csv')\n",
        "\n",
        "#print(titanic_data.isnull().sum())\n",
        "# Handle missing values\n",
        "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)\n",
        "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "#sex = pd.get_dummies(train['Sex'],dtype=int)\n",
        "titanic_data = pd.get_dummies(titanic_data, columns=['Sex', 'Embarked'], dtype=int)\n",
        "\n",
        "# Select features and target variable\n",
        "#X = titanic_data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
        "X = titanic_data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = titanic_data[['Survived']]\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "# Step 4: Split the Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Train the KNN Model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # You can tune n_neighbors\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Make Predictions\n",
        "y_pred = knn.predict(X_test)\n",
        "#print(\"Predicted Values:\")\n",
        "#print(y_pred )\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h_b1vtSbXw-",
        "outputId": "8eaf28f5-df06-4ced-9835-9e681995bdbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pclass        Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
            "0         3  22.000000      1      0   7.2500           0         1   \n",
            "1         1  38.000000      1      0  71.2833           1         0   \n",
            "2         3  26.000000      0      0   7.9250           1         0   \n",
            "3         1  35.000000      1      0  53.1000           1         0   \n",
            "4         3  35.000000      0      0   8.0500           0         1   \n",
            "..      ...        ...    ...    ...      ...         ...       ...   \n",
            "886       2  27.000000      0      0  13.0000           0         1   \n",
            "887       1  19.000000      0      0  30.0000           1         0   \n",
            "888       3  29.699118      1      2  23.4500           1         0   \n",
            "889       1  26.000000      0      0  30.0000           0         1   \n",
            "890       3  32.000000      0      0   7.7500           0         1   \n",
            "\n",
            "     Embarked_C  Embarked_Q  Embarked_S  \n",
            "0             0           0           1  \n",
            "1             1           0           0  \n",
            "2             0           0           1  \n",
            "3             0           0           1  \n",
            "4             0           0           1  \n",
            "..          ...         ...         ...  \n",
            "886           0           0           1  \n",
            "887           0           0           1  \n",
            "888           0           0           1  \n",
            "889           1           0           0  \n",
            "890           0           1           0  \n",
            "\n",
            "[891 rows x 10 columns]\n",
            "     Survived\n",
            "0           0\n",
            "1           1\n",
            "2           1\n",
            "3           1\n",
            "4           0\n",
            "..        ...\n",
            "886         0\n",
            "887         1\n",
            "888         0\n",
            "889         1\n",
            "890         0\n",
            "\n",
            "[891 rows x 1 columns]\n",
            "\n",
            "Model Accuracy: 0.7095\n",
            "Confusion Matrix:\n",
            "[[87 18]\n",
            " [34 40]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-4fa4d58b2b6f>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)\n",
            "<ipython-input-9-4fa4d58b2b6f>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sklearn Pipeline Implementation**"
      ],
      "metadata": {
        "id": "0v6QLYCxh2mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('titanic.csv')\n",
        "\n",
        "#print(\"Original DataFrame:\")\n",
        "#print(data)\n",
        "#print(data.shape)\n",
        "\n",
        "\n",
        "def impute_embarked(X):\n",
        "    X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])  # Fill missing values\n",
        "    return X\n",
        "\n",
        "# Custom function to create the FamilySize feature\n",
        "def create_family_size(X):\n",
        "    X['FamilySize'] = X['SibSp'] + X['Parch'] + 1  # Adding 1 for the individual themselves\n",
        "    return X\n",
        "\n",
        "# Custom function to drop specified columns\n",
        "def drop_columns(X):\n",
        "    return X.drop(['SibSp', 'Parch'], axis=1)\n",
        "\n",
        "# Function to create FamilySize and drop SibSp and Parch columns\n",
        "def family_size(X):\n",
        "    X = create_family_size(X)\n",
        "    X = drop_columns(X)\n",
        "    return X\n",
        "\n",
        "# Create pipelines for Age\n",
        "age_pipeline = Pipeline(steps=[\n",
        "    ('age_imputer', SimpleImputer(strategy='mean')),  # Impute Age\n",
        "    ('age_scaler', MinMaxScaler())  # Scale Age\n",
        "])\n",
        "\n",
        "fare_pipeline = Pipeline(steps=[\n",
        "    #('fare_imputer', SimpleImputer(strategy='mean')),  # Impute Fare\n",
        "    ('fare_scaler', MinMaxScaler())  # Scale Fare\n",
        "])\n",
        "\n",
        "family_size_pipeline = Pipeline(steps=[\n",
        "    ('family_size_creator', FunctionTransformer(family_size)),\n",
        "    ('family_size_scaler', MinMaxScaler()),  # Scale Family_Size\n",
        "])\n",
        "\n",
        "embarked_pipeline = Pipeline(steps=[\n",
        "    ('embarked_imputer', FunctionTransformer(impute_embarked)),  # Impute Embarked\n",
        "    ('embarked_onehot', OneHotEncoder())  # One-hot encode Embarked\n",
        "])\n",
        "\n",
        "# Create a ColumnTransformer to preprocess the data\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('age_encoder', age_pipeline, ['Age']),\n",
        "    ('fare_encoder', fare_pipeline, ['Fare']),\n",
        "    ('family_size', family_size_pipeline, ['SibSp', 'Parch']),  # Process FamilySize\n",
        "    ('embarked_encoder', embarked_pipeline, ['Embarked']),\n",
        "    ('sex_encoder', OneHotEncoder(), ['Sex']),\n",
        "    ('Pclass_scaler', MinMaxScaler(), ['Pclass']),  # Scale Pclass\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create a complete pipeline that includes preprocessing and the classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),  # Preprocessing steps\n",
        "    ('classifier', KNeighborsClassifier(n_neighbors=5))  # KNN Classifier\n",
        "])\n",
        "\n",
        "X = data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "print(type(X_train))\n",
        "print(type(y_train))\n",
        "print(type(X_test))\n",
        "print(type(y_test))\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Predicted Values:\")\n",
        "print(y_pred)\n",
        "print(y_pred.shape)\n",
        "print(type(y_pred))\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2FbXPYah0pj",
        "outputId": "5e2f6991-3b08-477b-b55c-5a0de6df92d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
            "331       1    male  45.5      0      0   28.5000        S\n",
            "733       2    male  23.0      0      0   13.0000        S\n",
            "382       3    male  32.0      0      0    7.9250        S\n",
            "704       3    male  26.0      1      0    7.8542        S\n",
            "813       3  female   6.0      4      2   31.2750        S\n",
            "..      ...     ...   ...    ...    ...       ...      ...\n",
            "106       3  female  21.0      0      0    7.6500        S\n",
            "270       1    male   NaN      0      0   31.0000        S\n",
            "860       3    male  41.0      2      0   14.1083        S\n",
            "435       1  female  14.0      1      2  120.0000        S\n",
            "102       1    male  21.0      0      1   77.2875        S\n",
            "\n",
            "[712 rows x 7 columns]\n",
            "331    0\n",
            "733    0\n",
            "382    0\n",
            "704    0\n",
            "813    0\n",
            "      ..\n",
            "106    1\n",
            "270    0\n",
            "860    0\n",
            "435    1\n",
            "102    0\n",
            "Name: Survived, Length: 712, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "Predicted Values:\n",
            "[0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
            " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1\n",
            " 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1]\n",
            "(179,)\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Model Accuracy: 0.80\n",
            "Confusion Matrix:\n",
            "[[90 15]\n",
            " [21 53]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('titanic.csv')\n",
        "\n",
        "#print(\"Original DataFrame:\")\n",
        "#print(data)\n",
        "#print(data.shape)\n",
        "\n",
        "def impute_embarked(X):\n",
        "    X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])  # Fill missing values\n",
        "    return X\n",
        "\n",
        "# Custom function to create the FamilySize feature\n",
        "def create_family_size(X):\n",
        "    X['FamilySize'] = X['SibSp'] + X['Parch'] + 1  # Adding 1 for the individual themselves\n",
        "    return X\n",
        "\n",
        "# Custom function to drop specified columns\n",
        "def drop_columns(X):\n",
        "    return X.drop(['SibSp', 'Parch'], axis=1)\n",
        "\n",
        "# Function to create FamilySize and drop SibSp and Parch columns\n",
        "def family_size(X):\n",
        "    X = create_family_size(X)\n",
        "    print(X)\n",
        "    X = drop_columns(X)\n",
        "    print(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "# Create pipelines for Age\n",
        "age_pipeline = Pipeline(steps=[\n",
        "    ('age_imputer', SimpleImputer(strategy='mean')),  # Impute Age\n",
        "    ('age_scaler', MinMaxScaler())  # Scale Age\n",
        "])\n",
        "\n",
        "fare_pipeline = Pipeline(steps=[\n",
        "    #('fare_imputer', SimpleImputer(strategy='mean')),  # Impute Fare\n",
        "    ('fare_scaler', MinMaxScaler())  # Scale Fare\n",
        "])\n",
        "\n",
        "family_size_pipeline = Pipeline(steps=[\n",
        "    ('family_size_creator', FunctionTransformer(family_size)),\n",
        "    ('family_size_scaler', MinMaxScaler()),  # Scale Family_Size\n",
        "])\n",
        "\n",
        "embarked_pipeline = Pipeline(steps=[\n",
        "    ('embarked_imputer', FunctionTransformer(impute_embarked)),  # Impute Embarked\n",
        "    ('embarked_onehot', OneHotEncoder())  # One-hot encode Embarked\n",
        "])\n",
        "\n",
        "# Create a ColumnTransformer to preprocess the data\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('age_encoder', age_pipeline, ['Age']),\n",
        "    ('fare_encoder', fare_pipeline, ['Fare']),\n",
        "    ('family_size', family_size_pipeline, ['SibSp', 'Parch']),  # Process FamilySize\n",
        "    ('embarked_encoder', embarked_pipeline, ['Embarked']),\n",
        "    ('sex_encoder', OneHotEncoder(), ['Sex']),\n",
        "    ('Pclass_scaler', MinMaxScaler(), ['Pclass']),  # Scale Pclass\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create a complete pipeline that includes preprocessing and the classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),  # Preprocessing steps\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # RandomForest Classifier\n",
        "])\n",
        "\n",
        "X = data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = data['Survived']\n",
        "print('-----------------')\n",
        "print(X)\n",
        "print(y)\n",
        "print('-----------------')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "print(type(X_train))\n",
        "print(type(y_train))\n",
        "print(type(X_test))\n",
        "print(type(y_test))\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Predicted Values:\")\n",
        "print(y_pred)\n",
        "print(y_pred.shape)\n",
        "print(type(y_pred))\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQKQyHMiIh4y",
        "outputId": "64fec96a-6c42-4c30-b288-f7a24a543378"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
            "0         3    male  22.0      1      0   7.2500        S\n",
            "1         1  female  38.0      1      0  71.2833        C\n",
            "2         3  female  26.0      0      0   7.9250        S\n",
            "3         1  female  35.0      1      0  53.1000        S\n",
            "4         3    male  35.0      0      0   8.0500        S\n",
            "..      ...     ...   ...    ...    ...      ...      ...\n",
            "886       2    male  27.0      0      0  13.0000        S\n",
            "887       1  female  19.0      0      0  30.0000        S\n",
            "888       3  female   NaN      1      2  23.4500        S\n",
            "889       1    male  26.0      0      0  30.0000        C\n",
            "890       3    male  32.0      0      0   7.7500        Q\n",
            "\n",
            "[891 rows x 7 columns]\n",
            "0      0\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      0\n",
            "      ..\n",
            "886    0\n",
            "887    1\n",
            "888    0\n",
            "889    1\n",
            "890    0\n",
            "Name: Survived, Length: 891, dtype: int64\n",
            "-----------------\n",
            "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
            "331       1    male  45.5      0      0   28.5000        S\n",
            "733       2    male  23.0      0      0   13.0000        S\n",
            "382       3    male  32.0      0      0    7.9250        S\n",
            "704       3    male  26.0      1      0    7.8542        S\n",
            "813       3  female   6.0      4      2   31.2750        S\n",
            "..      ...     ...   ...    ...    ...       ...      ...\n",
            "106       3  female  21.0      0      0    7.6500        S\n",
            "270       1    male   NaN      0      0   31.0000        S\n",
            "860       3    male  41.0      2      0   14.1083        S\n",
            "435       1  female  14.0      1      2  120.0000        S\n",
            "102       1    male  21.0      0      1   77.2875        S\n",
            "\n",
            "[712 rows x 7 columns]\n",
            "331    0\n",
            "733    0\n",
            "382    0\n",
            "704    0\n",
            "813    0\n",
            "      ..\n",
            "106    1\n",
            "270    0\n",
            "860    0\n",
            "435    1\n",
            "102    0\n",
            "Name: Survived, Length: 712, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "     SibSp  Parch  FamilySize\n",
            "331      0      0           1\n",
            "733      0      0           1\n",
            "382      0      0           1\n",
            "704      1      0           2\n",
            "813      4      2           7\n",
            "..     ...    ...         ...\n",
            "106      0      0           1\n",
            "270      0      0           1\n",
            "860      2      0           3\n",
            "435      1      2           4\n",
            "102      0      1           2\n",
            "\n",
            "[712 rows x 3 columns]\n",
            "     FamilySize\n",
            "331           1\n",
            "733           1\n",
            "382           1\n",
            "704           2\n",
            "813           7\n",
            "..          ...\n",
            "106           1\n",
            "270           1\n",
            "860           3\n",
            "435           4\n",
            "102           2\n",
            "\n",
            "[712 rows x 1 columns]\n",
            "     SibSp  Parch  FamilySize\n",
            "709      1      1           3\n",
            "439      0      0           1\n",
            "840      0      0           1\n",
            "720      0      1           2\n",
            "39       1      0           2\n",
            "..     ...    ...         ...\n",
            "433      0      0           1\n",
            "773      0      0           1\n",
            "25       1      5           7\n",
            "84       0      0           1\n",
            "10       1      1           3\n",
            "\n",
            "[179 rows x 3 columns]\n",
            "     FamilySize\n",
            "709           3\n",
            "439           1\n",
            "840           1\n",
            "720           2\n",
            "39            2\n",
            "..          ...\n",
            "433           1\n",
            "773           1\n",
            "25            7\n",
            "84            1\n",
            "10            3\n",
            "\n",
            "[179 rows x 1 columns]\n",
            "Predicted Values:\n",
            "[0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1\n",
            " 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1]\n",
            "(179,)\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Model Accuracy: 0.82\n",
            "Confusion Matrix:\n",
            "[[91 14]\n",
            " [19 55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Task\n",
        "\n",
        "*  Extend the traditional implemenetation by including the EDA steps performed in the Sklearn Pipeline implementation.\n",
        "*  Analyse the output of the EDA steps performed using the Sklearn Preprocessing and Pipeline functions and investigate whether there are any logical errors or not.\n",
        "*  Apply cross-valiadation using 5-folds and display both fold wise and overall accuracy.\n",
        "*  Perform the steps mentioned above on the following dataset\n",
        "\n",
        "https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease"
      ],
      "metadata": {
        "id": "Vu7nZz_DrFFY"
      }
    }
  ]
}