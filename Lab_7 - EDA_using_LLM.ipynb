{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimrancomsats/ProgrammingforAI_SPRING25/blob/main/EDA_using_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA using LLM**\n",
        "* ChatGPT LLM (PandasLLM)\n",
        "* Gemini LLM  \n"
      ],
      "metadata": {
        "id": "wyI97r2ai6eW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas pandas-llm google-generativeai"
      ],
      "metadata": {
        "id": "C0DLNiRHDB1w"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pandas_llm import PandasLLM\n",
        "\n",
        "# Data\n",
        "# Please note that these names, ages, and donations are randomly generated\n",
        "# and do not correspond to real individuals or their donations.\n",
        "data = [('John Doe', 25, 50),\n",
        "        ('Jane Smith', 38, 70),\n",
        "        ('Alex Johnson', 45, 80),\n",
        "        ('Jessica Brown', 60, 40),\n",
        "        ('Michael Davis', 22, 90),\n",
        "        ('Emily Wilson', 30, 60),\n",
        "        ('Daniel Taylor', 35, 75),\n",
        "        ('Sophia Moore', 40, 85),\n",
        "        ('David Thomas', 50, 65),\n",
        "        ('Olivia Jackson', 29, 55)]\n",
        "df = pd.DataFrame(data, columns=['name', 'age', 'donation'])\n",
        "\n",
        "api_key = \"OPENAI Key\"\n",
        "\n",
        "conv_df = PandasLLM(data=df, llm_api_key = api_key)\n",
        "result = conv_df.prompt(\"What is the average donation of people older than 40 who donated more than $50?\")\n",
        "code = conv_df.code_block\n",
        "\n",
        "print(f\"Executing the following expression of type {type(result)}:\\n{code}\\n\\nResult is:\\n {result}\\n\")\n",
        "# Executing the following expression of type <class 'numpy.float64'>:\n",
        "# result = df.loc[(df['age'] > 40) & (df['donation'] > 50), 'donation'].mean()\n",
        "\n",
        "# Result is:\n",
        "#  72.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzJHvIpe02aj",
        "outputId": "f00b8efa-5d1f-473d-c2ee-9737063ec3d9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing the following expression of type <class 'str'>:\n",
            "\n",
            "\n",
            "Result is:\n",
            " Please try later\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-f1126e91276a>:22: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  conv_df = PandasLLM(data=df, llm_api_key = api_key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "from getpass import getpass\n",
        "\n",
        "# Get your Gemini API key\n",
        "genai.configure(api_key=\"GOOGLE API Key\")\n",
        "\n",
        "# Read Dataset into DataFrame\n",
        "titanic = pd.read_csv(\"/content/titanic.csv\")\n",
        "\n",
        "# Define function to ask Gemini LLM\n",
        "def ask_gemini(prompt, titanic):\n",
        "    system_prompt = f\"\"\"You are a Python pandas expert.\n",
        "You are given a pandas DataFrame named `titanic`. Write Python code that answers the question below.\n",
        "\n",
        "Question: {prompt}\n",
        "\"\"\"\n",
        "    model = genai.GenerativeModel(\"models/gemini-1.5-pro-001\")  # Use valid model name\n",
        "    response = model.generate_content(system_prompt)\n",
        "    print(response)\n",
        "    code = response.text.strip(\"```python\").strip(\"```\")\n",
        "    return code\n",
        "\n",
        "# Ask your question\n",
        "question = \"How many missing values are there in the age column?\"\n",
        "code = ask_gemini(question, titanic)\n",
        "\n",
        "print(\"ðŸ”§ Generated code:\\n\")\n",
        "print(code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "FjEHvf-oaCYY",
        "outputId": "451b7348-4eae-41e7-c88c-4c5e98e0bfe9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"text\": \"```python\\ntitanic['Age'].isnull().sum()\\n```\"\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"index\": 0,\n",
            "          \"safety_ratings\": [\n",
            "            {\n",
            "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
            "              \"probability\": \"NEGLIGIBLE\"\n",
            "            },\n",
            "            {\n",
            "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
            "              \"probability\": \"NEGLIGIBLE\"\n",
            "            },\n",
            "            {\n",
            "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
            "              \"probability\": \"NEGLIGIBLE\"\n",
            "            },\n",
            "            {\n",
            "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
            "              \"probability\": \"NEGLIGIBLE\"\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 43,\n",
            "        \"candidates_token_count\": 13,\n",
            "        \"total_token_count\": 56\n",
            "      },\n",
            "      \"model_version\": \"gemini-1.5-pro-001\"\n",
            "    }),\n",
            ")\n",
            "ðŸ”§ Generated code:\n",
            "\n",
            "\n",
            "titanic['Age'].isnull().sum()\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titanic['Age'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP8MnGj_1x6u",
        "outputId": "2ce6275f-dd9b-4209-e396-4814f1fa402a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(177)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "from getpass import getpass\n",
        "\n",
        "# Get your Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"GOOGLE API Key\"\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "# Read Dataset into DataFrame\n",
        "titanic = pd.read_csv(\"/content/titanic.csv\")\n",
        "\n",
        "# Define function to ask Gemini LLM\n",
        "def ask_gemini(prompt, titanic):\n",
        "    system_prompt = f\"\"\"You are a Python pandas expert.\n",
        "You are given a pandas DataFrame named `titanic`. Write Python code that answers the question below.\n",
        "Assign the output to a variable called `result1`. Only return valid Python code.\n",
        "\n",
        "Question: {prompt}\n",
        "\"\"\"\n",
        "    model = genai.GenerativeModel(\"models/gemini-1.5-pro-001\")  # Use valid model name\n",
        "    response = model.generate_content(system_prompt)\n",
        "    code = response.text.strip(\"```python\").strip(\"```\")\n",
        "    return code\n",
        "\n",
        "# Ask your question\n",
        "question = \"How many distinct ages are there in the dataset?\"\n",
        "code = ask_gemini(question, titanic)\n",
        "\n",
        "print(\"ðŸ”§ Generated code:\\n\")\n",
        "print(code)\n",
        "\n",
        "# Execute the code\n",
        "local_vars = {\"titanic\": titanic}\n",
        "#print(local_vars)\n",
        "exec(code, local_vars)\n",
        "if \"result1\" in local_vars:\n",
        "  print(local_vars[\"result1\"])\n",
        "\n",
        "# Show result if available\n",
        "#if \"result\" in local_vars:\n",
        "    #from IPython.display import display\n",
        "    #display(local_vars[\"result\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "7hGiUxY3d1lC",
        "outputId": "fca4d155-2bad-48aa-ddb0-072d43db6758"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”§ Generated code:\n",
            "\n",
            "\n",
            "result1 = len(titanic['Age'].unique())\n",
            "\n",
            "89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Task\n",
        "\n",
        "* Get your OpenAI and Gemini API keys, and execute the above code.\n",
        "* Modify the prompt and analyze the LLM's responses to various prompts.\n",
        "* Research the different versions of ChatGPT and Gemini LLMs available, and determine which version performs best for the EDA process.\n",
        "* Exlpore the PandasAI library (https://pypi.org/project/pandasai/) and how it is different from PandasLLM.  \n",
        "* Apply EDA using an LLM on the following dataset.\n",
        "\n",
        "https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease"
      ],
      "metadata": {
        "id": "Vu7nZz_DrFFY"
      }
    }
  ]
}
